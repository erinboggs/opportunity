names(oppdata2)
x <- subset(oppdata[3:12], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA")
pca1 = prcomp(x, scale. = T)
rotation <- data.frame(pca1$rotation[,1])
weights1 <-
ggplot(data = rotation, aes(x = pca1.rotation...1., y = row.names(rotation))) +
geom_point() +
xlim(-0.4,0.3) +
labs(x = "Weight in first principal component", y = NULL, title = "Original")
y <- subset(oppdata2[c(3:7,8:14)],
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA")
pca2 = prcomp(y, scale. = T)
rotation2 <- data.frame(pca2$rotation[,1])
weights2 <-
ggplot(data = rotation2, aes(x = pca2.rotation...1., y = row.names(rotation2))) +
geom_point() +
xlim(-0.4,0.3) +
labs(x = "Weight in first principal component", y = NULL, title = "With job growth + access + diversity")
library(gridExtra)
win.metafile("Principal-components.emf", width = 10, pointsize = 9)
grid.arrange(weights1, weights2, ncol = 1, nrow = 2)
dev.off()
y <- subset(oppdata2[c(3:7,8:14)],
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA")
summary(y)
y <- subset(oppdata2[c(3:7,8:14)], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA")
pca2 = prcomp(y, scale. = T)
rotation2 <- data.frame(pca2$rotation[,1])
weights2 <-
ggplot(data = rotation2, aes(x = pca2.rotation...1., y = row.names(rotation2))) +
geom_point() +
xlim(-0.4,0.3) +
labs(x = "Weight in first principal component", y = NULL, title = "With job growth + access + diversity")
library(gridExtra)
win.metafile("Principal-components.emf", width = 10, pointsize = 9)
grid.arrange(weights1, weights2, ncol = 1, nrow = 2)
dev.off()
names(y)
oppdata2[c(3:7,8:14)]
names(oppdata2[c(3:7,8:14)])
y <- subset(oppdata2[c(3:7,9:14)], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA")
pca2 = prcomp(y, scale. = T)
rotation2 <- data.frame(pca2$rotation[,1])
weights2 <-
ggplot(data = rotation2, aes(x = pca2.rotation...1., y = row.names(rotation2))) +
geom_point() +
xlim(-0.4,0.3) +
labs(x = "Weight in first principal component", y = NULL, title = "With job growth + access + diversity")
library(gridExtra)
win.metafile("Principal-components.emf", width = 10, pointsize = 9)
grid.arrange(weights1, weights2, ncol = 1, nrow = 2)
dev.off()
names(y)
names(oppdata2)
oppdata2[8]
head(oppdata2[8])
oppdata2[c(3:7,9:14)]
head(oppdata2[c(3:7,9:14)])
names(oppdata2[c(3:7,9:14)])
y <- subset(oppdata2[c(3:7,9:14)], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA")
y <- subset(oppdata2[c(3:7,9:14)], vacancy != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA")
pca2 = prcomp(y, scale. = T)
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA")
pca2 = prcomp(y, scale. = T)
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA" &
job_diversity_index != "NA")
pca2 = prcomp(y, scale. = T)
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA" &
job_diversity_index != "NA")
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" & unemployemt != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA" &
job_diversity_index != "NA")
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" & unemployment != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA" &
job_diversity_index != "NA")
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" | unemployment != "NA" |
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" & jobchange != "NA" &
job_diversity_index != "NA")
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" |
Total.Mathematics.Avg.Scale.Score != "NA" |
Total.Reading.Average.Scale.Score != "NA" | jobchange != "NA" &
job_diversity_index != "NA")
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" &
unemployment != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA" &
job_diversity_index != "NA")
summary(y)
y <- subset(oppdata2[c(3:7,9:14)], poverty != "NA" &
owneroccupied != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA" &
job_diversity_index != "NA")
summary(y)
y <- subset(oppdata2[3:14], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA")
summary(y)
y <- subset(oppdata2[3:14], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA")[c(1:7,9:14)]
subset(oppdata2[3:14], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA")
names(subset(oppdata2[3:14], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA"))
y <- subset(oppdata2[3:14], commutetime != "NA" &
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA")[c(1:5,7:12)]
pca2 = prcomp(y, scale. = T)
rotation2 <- data.frame(pca2$rotation[,1])
weights2 <-
ggplot(data = rotation2, aes(x = pca2.rotation...1., y = row.names(rotation2))) +
geom_point() +
xlim(-0.4,0.3) +
labs(x = "Weight in first principal component", y = NULL, title = "With job growth + access + diversity")
library(gridExtra)
win.metafile("Principal-components.emf", width = 10, pointsize = 9)
grid.arrange(weights1, weights2, ncol = 1, nrow = 2)
dev.off()
write.csv(variables, variables.csv, row.names = F)
write.csv(oppdata2, index-values.csv, row.names = F)
write.csv(variables, "variables.csv", row.names = F)
write.csv(oppdata2, "index-values.csv", row.names = F)
#Load all the libraries and census data
library(ggplot2)
library(reshape)
library(plyr)
library(acs)
library(maps)
library(maptools)
require(slidify)
slidify('index.Rmd')
names(variables)
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
head(choropleth)
choropleth=merge(CTTracts, variables, by.x = "id", by.y="geo")
choropleth=choropleth[order(choropleth$order), ]
head(choropleth)
for(i in 1:1) {
tmp <- names(variables)
breaks <- classIntervals(variables[[tmp[i+7]]], n=5, style="quantile")
choropleth[[tmp[i+7]]]=cut(choropleth[[tmp[i+7]]],
breaks=breaks$brks,
include.lowest=T, dig.lab = T)
#Make the map
ggplot(data = choropleth, aes(long, lat, group = group)) +
geom_polygon(aes(fill = choropleth[[tmp[i+7]]])) +
scale_x_continuous(breaks = NULL) +
scale_y_continuous(breaks = NULL) +
labs(x = NULL, y = NULL, title = tmp[i+7]) +
coord_equal() +
scale_fill_brewer(palette = "Purples", name = "Values") +
theme_minimal()
}
slidify('index.Rmd')
slidify('index.Rmd')
length(variables)
slidify('index.Rmd')
vnames
slidify('index.Rmd')
slidify('index.Rmd')
vnames[2]
vnames[0]
vnames[1]
slidify('index.Rmd')
ggplot(data = variables) +
geom_density(aes(x = variables[[tmp[6]]]))
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
require(slidify)
subset(oppdata[3:13],
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA")
rm(oppdata2)
x <- subset(oppdata[3:13],
Total.Mathematics.Avg.Scale.Score != "NA" &
Total.Reading.Average.Scale.Score != "NA" &
jobchange != "NA")
print(xtable(round(cor(x),2)), type = "html")
round(cor(x),2)
cor(oppdata[3:13], na.rm = T)
cor(x, na.rm = T)
cor(x, use = na.or.complete)
cor(x, use = "na.or.complete")
rm(x)
rm(y)
rm(z)
print(xtable(round(cor(x, use = "na.or.complete"),2)), type = "html")
library(xtable)
print(xtable(round(cor(x, use = "na.or.complete"),2)), type = "html")
print(xtable(round(cor(oppdata[3:13], use = "na.or.complete"),2)), type = "html")
print(xtable(round(cor(oppdata[3:14], use = "na.or.complete"),2)), type = "html")
prcomp(oppdata[3:14], scale. = T)
prcomp(oppdata[3:14], scale. = T, na.action = "na.omit")
require(slidify)
slidify('index.Rmd')
pca1 = prcomp(na.omit(oppdata[3:14]), scale. = T)
rm(x)
pca1 = prcomp(na.omit(oppdata[3:14]), scale. = T)
print(summary(pca1))
plot(prcomp(na.omit(oppdata[3:14]), scale = T))
plot(prcomp(na.omit(oppdata[3:14]), scale = T), title = "Principal components")
plot(prcomp(na.omit(oppdata[3:14]), scale = T), main = "Principal components")
print(summary(pca1))
rotation <- data.frame(pca1$rotation[,1])
qplot(data = rotation, x = pca1.rotation...1., y = row.names(rotation)) +
labs(x = "Weight in first principal component", y = NULL)
lm(oppdata$poverty ~ oppdata$index)
summary(lm(oppdata$index ~ oppdata$poverty))
slidify('index.Rmd')
require(slidify)
slidify('index.Rmd')
print(xtable(summary(variables[3:8])), type = "html", include.rownames = F)
print(xtable(summary(variables[3:8])), type = "html", include.rownames = F, size = "small")
slidify('index.Rmd')
print(xtable(summary(variables[3:8])), type = "html", include.rownames = F, size = "small", tabular.environment="tabularx")
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
summary(variables[3,9:13]))
summary(variables[3,9:13])
summary(variables[c(3,9:13)])
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
slidify('index.Rmd')
colnames(sumtmp)[3:13]
slidify('index.Rmd')
slidify('index.Rmd')
require(slidify)
slidify('index.Rmd')
warnings()
slidify('index.Rmd')
require(slidify)
subset(read.csv('totalcrime.csv'), Year == 2010)
subset(read.csv('totalcrime.csv'), Year == 2010)
names(subset(read.csv('totalcrime.csv'), Year == 2010))
subset(read.csv('totalcrime.csv'),
Year == 2010)[c("Town","Total.crime.Rate")]
variables <- merge(variables,
subset(read.csv('totalcrime.csv'),
Year == 2010)[c("Town","Total.crime.Rate")],
by.x = "NAME10_1",
by.y = "Town",
all.x = T)
slidify('index.Rmd')
warnings()
crime$inverse.pct = 1 - (crime$Total.crime.Rate / 10000)
#Load crime data, take only 2010 year
crime <- subset(read.csv('totalcrime.csv'), Year == 2010)
#Convert crime rates into percentage, take 1 - percent
crime$inverse.pct = 1 - (crime$Total.crime.Rate / 10000)
summary(crime$inverse.pct)
crime <- subset(read.csv('totalcrime.csv'), Year == 2010)
#Convert crime rates into percentage, take 1 - percent
crime$inverse.pct = 1 - (crime$Total.crime.Rate / 100000)
summary(crime$inverse.pct)
slidify('index.Rmd')
vnames <- c("% adults with college degree",
"% not receiving public assistance",
"% not in poverty",
"% employed",
"% living in owner-occupied housing",
"% housing that is not vacant",
"Employment access index",
"Job diversity index",
"% change in jobs (2009-12)",
"3rd grade math, avg. scale scores",
"3rd grade reading, avg. scale scores",
"Lack of crime (1 - rate)")
length(variables)
names(variables)
slidify('index.Rmd')
rowMeans(oppdata[3:14], na.rm = T)
slidify('index.Rmd')
warnings()
slidify('index.Rmd')
slidify('index.Rmd')
crime[c("Town","inverse.pct")]
crime[c("Town","inverse.pct")]
slidify('index.Rmd')
slidify('index.Rmd')
colnames(sumtmp2)[3:14]
vnames
slidify('index.Rmd')
slidify('index.Rmd')
data.frame(pca1$rotation[,1])
prcomp(na.omit(oppdata[3:14]), scale. = T)
require(slidify)
slidify('index.Rmd')
data.frame(pca1$rotation[,1])
slidify('index.Rmd')
slidify('index.Rmd')
write.csv(variables, "index-variables.csv", row.names = F)
write.csv(oppdata, "opportunity-index.csv", row.names = F)
slidify('index.Rmd')
library(classInt)
classIntervals(oppdata$index, n=5, style="quantile")
write.csv(classIntervals(oppdata$index, n=5, style="quantile"),'breaks.csv',row.names = F)
write.csv(as.data.frame(classIntervals(oppdata$index, n=5, style="quantile")),'breaks.csv',row.names = F)
breaks <- classIntervals(oppdata$index, n=5, style="quantile")
breaks
write.csv(breaks,'breaks.csv')
write.csv(data.frame(breaks),'breaks.csv')
write.csv(as.list(breaks),'breaks.csv')
breaks
write.csv(variables, "index-variables.csv", row.names = F)
require(slidify)
slidify('index.Rmd')
require(slidify)
slidify('index.Rmd')
require(slidify)
write.csv(variables, "index-variables.csv", row.names = F)
print(xtable(summary(sumtmp[10:14])), type = "html", include.rownames = F, size = "small")
library(ggplot2)
library(reshape)
library(plyr)
library(acs)
library(maps)
library(maptools)
key = "ba67d3a427e1f785987b9c8bc59341bf7c8a7cc1"
api.key.install(key)
#Load the UConn tract and town-level shapefiles for maps
CTTracts <- readShapeSpatial(fn="tractct_37800_0000_2010_s100_census_1_shp/wgs84/tractct_37800_0000_2010_s100_census_1_shp_wgs84")
CTTracts <- fortify(CTTracts, region = "NAME10")
CTTracts <- CTTracts[order(CTTracts$order),]
#Create tracts for the state
ct.tracts = geo.make(state = "CT", county = "*", tract = "*", check = F)
#Percent of population on public assistance
B19058 = acs.fetch(geography = ct.tracts, table.number = "B19058", col.names = "pretty", endyear = 2012)
B19058.rate = divide.acs(numerator=B19058[,2],denominator=B19058[,1])
B19058.tract = data.frame(geo=geography(B19058)[[1]],
publicassistance= 1 - as.numeric(estimate(B19058.rate)))
#Percent of population with college degree including associate degree
B23006 = acs.fetch(geography = ct.tracts, table.number = "B23006", col.names = "pretty", endyear = 2012)
B23006.rate = divide.acs(numerator=(B23006[,16]+B23006[,23]),denominator=B23006[,1])
B23006.tract = data.frame(geo=geography(B23006)[[1]],
college = as.numeric(estimate(B23006.rate)))
#Neighborhood poverty rate
B17017 = acs.fetch(geography = ct.tracts, table.number = "B17017", col.names = "pretty", endyear = 2012)
B17017.rate = divide.acs(numerator=B17017[,2], denominator=B17017[,1])
B17017.tract = data.frame(geo=geography(B17017)[[1]],
poverty= 1 - as.numeric(estimate(B17017.rate)))
#Unemployment rate
B23025 = acs.fetch(geography = ct.tracts, table.number = "B23025", col.names = "pretty")
B23025.rate = divide.acs(numerator=B23025[,5],denominator=B23025[,2])
B23025.tract = data.frame(geo=geography(B23025)[,1],
unemployment= 1 - as.numeric(estimate(B23025.rate)))
#Home ownership rate - percent of owner-occupied homes in housing stock
B25008 = acs.fetch(geography = ct.tracts, table.number = "B25008", col.names = "pretty", endyear = 2012)
B25008.rate = divide.acs(numerator=B25008[,2],denominator=B25008[,1])
B25008.tract = data.frame(geo=geography(B25008)[[1]],
owneroccupied= as.numeric(estimate(B25008.rate)))
#Neighborhood vacancy rate
B25002 = acs.fetch(geography = ct.tracts, table.number = "B25002", col.names = "pretty", endyear = 2012)
B25002.rate = divide.acs(numerator=B25002[,3],denominator=B25002[,1])
B25002.tract = data.frame(geo=geography(B25002)[[1]],
vacancy= 1 - as.numeric(estimate(B25002.rate)))
#Merge all the census data into a single table
variables <- merge(merge(merge(merge(merge(B23006.tract, B19058.tract), B17017.tract),B23025.tract),B25008.tract),B25002.tract)
#Convert the tract names to numbers to allow merge later with other files
variables$geo= gsub("Census Tract ", "", variables$geo)
variables$geo= gsub(", (Fairfield|Hartford|Litchfield|Middlesex|New Haven|New London|Tolland|Windham) County, Connecticut","", variables$geo)
#Load the employment access index data from the LAI dataset
#Group into tracts as weighted avg.
eai <- ddply(read.csv('lai_data_allCT_blkgrps.csv'),
.(tract),
summarise,
employment_access_index = weighted.mean(employment_access_index,households, na.rm = T),
job_diversity_index = weighted.mean(job_diversity_index, households, na.rm = T))
variables <- merge(variables,
eai,
by.x = "geo",
by.y = "tract",
all.x = T)
#Load the tract mapping from UConn
mapping <- read.csv('tractstowns2.csv')
#Add the town names to the tract-level data
variables <- merge(variables,
mapping[c("NAME10","NAME10_1")],
by.x = "geo", by.y = "NAME10", all.x = T)
#Load the qcew data
qcew <- read.csv('qcew-annual-averages.csv', na.strings = "*")
#Cast into new format to get growth rate in employment
qcew_t <- cast(qcew, Town ~ Year, value = "Annual.Average.Employment")
names(qcew_t) <- make.names(names(qcew_t))
qcew_t$jobchange = (qcew_t$X2012 - qcew_t$X2009) / as.numeric(qcew_t$X2009)
variables <- merge(variables,
qcew_t[c("Town","jobchange")],
by.x = "NAME10_1",
by.y = "Town",
all.x = T)
#Load the test scores data
#Needed to manually change code regional school districts
#Fill missing years for some towns, i.e. Newtown 2013
cmt <- read.csv('ctreports-2013-grade-3-cmt.csv', na.strings = "-")
#Merge avg. scale scores with rest of oppdata
variables <- merge(variables,
cmt[c("Group",
"Total.Mathematics.Avg.Scale.Score",
"Total.Reading.Average.Scale.Score")],
by.x = "NAME10_1",
by.y = "Group",
all.x = T)
#Load crime data, take only 2010 year
crime <- subset(read.csv('totalcrime.csv'), Year == 2010)
#Convert crime rates into percentage, take 1 - percent
crime$inverse.pct = 1 - (crime$Total.crime.Rate / 100000)
variables <- merge(variables,
crime[c("Town","inverse.pct")],
by.x = "NAME10_1",
by.y = "Town",
all.x = T)
#Create a list of all the variable names for pretty tables
vnames <- c("% adults with college degree",
"% not receiving public assistance",
"% not in poverty",
"% employed",
"% living in owner-occupied housing",
"% housing that is not vacant",
"Employment access index",
"Job diversity index",
"% change in jobs (2009-12)",
"3rd grade math, avg. scale scores",
"3rd grade reading, avg. scale scores",
"Lack of crime (1 - rate)")
library(xtable)
sumtmp <- variables
colnames(sumtmp)[3:14] <- vnames
print(xtable(summary(sumtmp[3:9])), type = "html", include.rownames = F, size = "small")
print(xtable(summary(sumtmp[10:14])), type = "html", include.rownames = F, size = "small")
write.csv(variables, "index-variables.csv", row.names = F)
slidify('index.Rmd')
library(classInt)
choropleth=merge(CTTracts, variables, by.x = "id", by.y="geo")
choropleth=choropleth[order(choropleth$order), ]
for(i in 3:length(variables)) {
tmp <- names(variables)
breaks <- classIntervals(variables[[tmp[i]]], n=5, style="quantile")
choropleth[[tmp[i]]]=cut(choropleth[[tmp[i]]],
breaks=breaks$brks,
include.lowest=T, dig.lab = T)
#Make the map
print(
ggplot(data = choropleth, aes(long, lat, group = group)) +
geom_polygon(aes(fill = choropleth[[tmp[i]]])) +
scale_x_continuous(breaks = NULL) +
scale_y_continuous(breaks = NULL) +
labs(x = NULL, y = NULL, title = vnames[i-2]) +
coord_equal() +
scale_fill_brewer(palette = "Oranges", name = "Values") +
theme_minimal())
}
warnings()
slidify('index.Rmd')
