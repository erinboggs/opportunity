---
title       : Opportunity Index
subtitle    : Updating CT Opportunity Index data
author      : Scott Gaul
job         : Community Indicators Project
framework   : minimal        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
mode        : selfcontained # {standalone, draft}
markdown    : kramdown
---

## Opportunity Index

If you just want to download the data, you can get it [here](https://github.com/sgaul/opportunity/blob/gh-pages/oppdata.csv).

If you want more on the index, here you go. 

The [Opportunity Index](http://kirwaninstitute.osu.edu/reports/2009/11_2009_CTOppMapping_FullReport.pdf) uses 10 variables; seven of these can be retrieved from the Census Bureau's American Community Survey:
* [Educational attainment for the population](http://factfinder2.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_11_5YR_B23006) (college and associates degrees)
* [Unemployment rates](http://factfinder2.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_12_5YR_B23025) (percent in labor force but unemployed)
* [Population on public assistance](http://factfinder2.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_11_5YR_B19058)
* [Mean commute time](http://factfinder2.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_12_5YR_B08135) (average time to commute for residents, using the method outlined [here](http://quickfacts.census.gov/qfd/meta/long_LFE305212.htm))
* [Vacancy rate](http://factfinder2.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_12_5YR_B25002) (percent vacant housing)
* [Poverty](http://factfinder2.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_12_5YR_B17017) (percent below poverty line)
* [Home ownership rate](http://factfinder2.census.gov/faces/tableservices/jsf/pages/productview.xhtml)

### Census data for neighborhoods

For 'neighborhood' data, the index uses census tracts which restricts the data source to the ACS 5-year estimates. I used the [acs.R package](http://cran.r-project.org/web/packages/acs/index.html) which uses the Census API to download data by tract for the entire state for each of these seven variables. The most recent set of 5-year estimates spans 2008 - 2012, but the script could be updated for different years as new data becomes available.

To keep each of the variables in the same 'direction' (more homeownership is 'good,' while more poverty is 'bad'), I converted the public assistance, poverty, unemployment and vacancy to the inverse percentage (i.e. 1 - rate). For the commute times, I multiplied by (-1) so that longer commute times are lower values. 

Below are summary stats for the census data components of the index:

```{r echo = FALSE, warning = FALSE, message = FALSE}
library(ggplot2)
library(reshape)
library(acs)
library(maps)
library(maptools)

#Set up Census API key
key = "ba67d3a427e1f785987b9c8bc59341bf7c8a7cc1"
api.key.install(key)

#Load the UConn tract and town-level shapefiles for maps
CTTracts <- readShapeSpatial(fn="tractct_37800_0000_2010_s100_census_1_shp/wgs84/tractct_37800_0000_2010_s100_census_1_shp_wgs84")
CTTracts <- fortify(CTTracts, region = "NAME10")
CTTracts <- CTTracts[order(CTTracts$order),]

#Create tracts for the state
ct.tracts = geo.make(state = "CT", county = "*", tract = "*", check = F)

#Percent of population on public assistance
B19058 = acs.fetch(geography = ct.tracts, table.number = "B19058", col.names = "pretty", endyear = 2012)

B19058.rate = divide.acs(numerator=B19058[,2],denominator=B19058[,1])

B19058.tract = data.frame(geo=geography(B19058)[[1]],
                              publicassistance= 1 - as.numeric(estimate(B19058.rate)))

#Percent of population with college degree including associate degree
B23006 = acs.fetch(geography = ct.tracts, table.number = "B23006", col.names = "pretty", endyear = 2012)

B23006.rate = divide.acs(numerator=(B23006[,16]+B23006[,23]),denominator=B23006[,1])

B23006.tract = data.frame(geo=geography(B23006)[[1]],
                              college = as.numeric(estimate(B23006.rate)))

#Neighborhood poverty rate
B17017 = acs.fetch(geography = ct.tracts, table.number = "B17017", col.names = "pretty", endyear = 2012)

B17017.rate = divide.acs(numerator=B17017[,2], denominator=B17017[,1])

B17017.tract = data.frame(geo=geography(B17017)[[1]], 
                     poverty= 1 - as.numeric(estimate(B17017.rate)))

#Unemployment rate
B23025 = acs.fetch(geography = ct.tracts, table.number = "B23025", col.names = "pretty")

B23025.rate = divide.acs(numerator=B23025[,5],denominator=B23025[,2])

B23025.tract = data.frame(geo=geography(B23025)[,1],
                              unemployment= 1 - as.numeric(estimate(B23025.rate)))

#Home ownership rate - percent of owner-occupied homes in housing stock
B25008 = acs.fetch(geography = ct.tracts, table.number = "B25008", col.names = "pretty", endyear = 2012)

B25008.rate = divide.acs(numerator=B25008[,2],denominator=B25008[,1])

B25008.tract = data.frame(geo=geography(B25008)[[1]],
                          owneroccupied= as.numeric(estimate(B25008.rate)))

#Mean commute time
B08013 = acs.fetch(geography = ct.tracts, table.number = "B08013", col.names = "pretty", endyear = 2012)
B99084 = acs.fetch(geography = ct.tracts, table.number = "B99084", col.names = "pretty", endyear = 2012)

B08013.rate = divide.acs(numerator=B08013[,1],denominator=B99084[,2])

B08013.tract = data.frame(geo=geography(B08013)[[1]],
                          commutetime= (-1) * as.numeric(estimate(B08013.rate)))

#Neighborhood vacancy rate
B25002 = acs.fetch(geography = ct.tracts, table.number = "B25002", col.names = "pretty", endyear = 2012)

B25002.rate = divide.acs(numerator=B25002[,3],denominator=B25002[,1])

B25002.tract = data.frame(geo=geography(B25002)[[1]],
                          vacancy= 1 - as.numeric(estimate(B25002.rate)))

oppdata <- data.frame(B23006.tract,
                      B19058.tract[2], 
                      B17017.tract[2],
                      B23025.tract[2],
                      B25008.tract[2],
                      B08013.tract[2],
                      B25002.tract[2],
                      check.names = F)

oppdata$geo= gsub("Census Tract ", "", oppdata$geo)
oppdata$geo= gsub(", (Fairfield|Hartford|Litchfield|Middlesex|New Haven|New London|Tolland|Windham) County, Connecticut","", oppdata$geo)

library(xtable)
#print(xtable(summary(oppdata[2:8])), type = "html")
print(summary(oppdata[2:8]))
```

The remaining variables - math and reading test scores and economic climate - aren't publicly available at the neighborhood level. 

### Town data for jobs and test scores

Math and reading scores are reported by the State Department of Education [at the school and district level](http://www.ctreports.com/). Since many children do not attend neighborhood schools, even if data were readily available it may  not accurately represent opportunity in a particular neighborhood. As a proxy, I used the average test scores for the school district of the town. Average test scores take into account the performance of all students, not just those crossing a particular threshold. The index also does not specify the grade level, so I opted to take 3rd grade reading and math scores as a fairly common milestone indicator. 

A few smaller districts did not have 2013 reports, so the most recent year available was used instead. Cornwall and Union did not have data for any of the past seven years. Scores for regional school districts are reported for each town in the region. 

'Economic climate' was defined for the Opportunity Index as 'the change in jobs within 5 miles from 2005 to 2008,' using data from ESRI Business Analyst. To get around relying on data from ESRI, I used the [Quarterly Census of Earnings and Wages](http://www1.ctdol.state.ct.us/lmi/) series from the Bureau of Labor Statistics. The data is available by town and is a direct census of employment from wage records. I used 2009 to 2012 as the timeframe, although this does not perfectly match the census data. 

As in the prior Opportunity Index, the job change data has some outlier values, particularly for small towns (such as Barkhamsted, where employment doubled from 616 to 1145 people over the three years) which you can see in the summary stats below.

```{r echo = FALSE, warning = FALSE, message = FALSE}
#Load the tract mapping from UConn
library(reshape)
mapping <- read.csv('tractstowns2.csv')

#Add the town names to the tract-level data
oppdata <- merge(oppdata, mapping[c("NAME10","NAME10_1")], by.x = "geo", by.y = "NAME10", all.x = T)

#Load the qcew data
qcew <- read.csv('qcew-annual-averages.csv', na.strings = "*")

#Cast into new format to get growth rate in employment
qcew_t <- cast(qcew, Town ~ Year, value = "Annual.Average.Employment")
names(qcew_t) <- make.names(names(qcew_t))
qcew_t$jobchange = (qcew_t$X2012 - qcew_t$X2009) / as.numeric(qcew_t$X2009)

oppdata <- merge(oppdata, 
                 qcew_t[c("Town","jobchange")], 
                 by.x = "NAME10_1", 
                 by.y = "Town", 
                 all.x = T)

#Load the test scores data
#Need to manually change code regional school districts
#Fill missing years for some towns, i.e. Newtown 2013
cmt <- read.csv('ctreports-2013-grade-3-cmt.csv', na.strings = "-")

#Merge avg. scale scores with rest of oppdata
oppdata <- merge(oppdata, 
                 cmt[c("Group",
                       "Total.Mathematics.Avg.Scale.Score",
                       "Total.Reading.Average.Scale.Score")], 
                 by.x = "NAME10_1", 
                 by.y = "Group", 
                 all.x = T)

library(xtable)
#print(xtable(summary(oppdata[10:12])), type = "html")
print(summary(oppdata[10:12]))
```

### Calculating z-scores for the index

The Opportunity Index uses z-scores to scale the variables and calculate the index. This is important because the interpretation of the z-scores depends on how the data are distributed. If data are distributed normally ('bell-curve' style), the z-scores tell us roughly how much of the data is below or above a certain z-score. You can then also compare z-scores for different bell-curve-shaped data sets - the z-scores mean the same thing if the underlying distributions have the same shape. 

The plots below show the distribution of each of the components of the index for the 833 census tracts in Connecticut. You can see that most are not bell-curve shaped. Rather, several are skewed, which reflects the general concentration of poverty, public assistance and related variables in a small set of neighborhoods within the state. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
ggplot(data = melt(oppdata)) + 
         geom_density(aes(x = value)) + 
         facet_wrap(~ variable, ncol = 2, scales = "free")
```

If the data are not normally distributed - if, for instance, they are skewed or there are multiple modes in the data - then the z-scores can be harder to interpret. And it's also harder to compare the z-scores across variables - a z-score of 2 for poverty doesn't mean the same thing as a z-score of 2 for commute time if they don't have the same-shaped distribution. 

This matters since the opportunity index is calculated using the average z-scores across all of the variables. If the variables have different distributions, then the z-scores will have different ranges and the z-scores won't have the same interpretation or influence on the final index values. 

The charts below show the standardized results for each variable - they report the z-scores between -/+2 standard deviations for each variable. You can see that variables like poverty, public assistance, unemployment tend to have similar shapes and are skewed positive - there are many above-average tracts, but a long tail of tracts with below-average scores on these variables.

```{r echo = FALSE, warning = FALSE, message = FALSE}
oppdata[3:12] <- scale(oppdata[3:12], center = T, scale = T)

ggplot(data = melt(oppdata)) +
  geom_density(aes(x = value)) +
  xlim(-2,2) +
  facet_wrap(~ variable, ncol = 2, scales = "free_y")
```

To see this visually, we can map each of the variables for the state. Several variables - like poverty, public assistance, unemployment - show similar patterns across tracts, while job growth and commute times are less similar. 

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 15, fig.width = 12}
#Merge with data
library(classInt)
choropleth=merge(CTTracts, melt(oppdata), by.x = "id", by.y="geo")
choropleth=choropleth[order(choropleth$order), ]
breaks <- classIntervals(melt(oppdata)$value, n=5, style="fisher")
choropleth$value=cut(choropleth$value, 
                      breaks=breaks$brks,
                      include.lowest=T, dig.lab = T)
#Make the map
ggplot(data = choropleth, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = value)) + 
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(x = NULL, y = NULL) + 
  coord_equal() +
  scale_fill_brewer(palette = "Purples", name = "Z-scores") +
  theme_minimal() + 
  facet_wrap(~ variable, ncol = 2)
```

The next step is to calculate the opportunity index as the average of the z-scores of the individual variables. 

Even this has some choices involved - the Kirwan Institute mapping uses [quintiles to color the maps](http://kirwaninstitute.osu.edu/reports/2009/11_2009_CTOppMapping_FullReport.pdf), which means 1/5th of the tracts will fall into each color category. The map below shows the updated index for the state using quintiles. 

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 12}
#Merge with data
oppdata$index = rowMeans(oppdata[3:12], na.rm = T)
write.csv(oppdata, "oppdata.csv", row.names = F)

library(classInt)
choropleth=merge(CTTracts, oppdata[c("geo","index")], 
                 by.x = "id", by.y="geo")
choropleth=choropleth[order(choropleth$order), ]
breaks <- classIntervals(oppdata$index, n=5, style="quantile")
choropleth$index=cut(choropleth$index, 
                      breaks=breaks$brks,
                      include.lowest=T, dig.lab = T)
#Make the map
ggplot(data = choropleth, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = index)) + 
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(x = NULL, y = NULL) + 
  coord_equal() +
  scale_fill_brewer(palette = "Purples", name = "Opportunty index\n(Z-scores - quintiles)") +
  theme_minimal(base_size = 14)
```

Another way of coloring the map would be to use [Jenks natural breaks](http://support.esri.com/en/knowledgebase/GISDictionary/term/natural%20breaks%20classification) method which looks for natural divisions in the data. The map below uses this coloring method for the same data.

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 12}
#Merge with data
choropleth=merge(CTTracts, oppdata[c("geo","index")], 
                 by.x = "id", by.y="geo")
choropleth=choropleth[order(choropleth$order), ]
breaks <- classIntervals(oppdata$index, n=5, style="jenks")
choropleth$index=cut(choropleth$index, 
                      breaks=breaks$brks,
                      include.lowest=T, dig.lab = T)
#Make the map
ggplot(data = choropleth, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = index)) + 
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(x = NULL, y = NULL) + 
  coord_equal() +
  scale_fill_brewer(palette = "Purples", name = "Opportunity index\n(Z-scores, Jenks)") +
  theme_minimal(base_size = 14)
```

This map reflects fewer areas of 'very low' opportunity, but more areas of 'low' and 'moderate' opportunity. Another way to see this is to plot the distribution of the index values for the tracts, including the breakpoints. The chart below shows the breakpoints using the quintiles. (Again, the overall distribution is skewed positive.)

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 3}
breaks <- classIntervals(oppdata$index, n=5, style="quantile")
ggplot(data = oppdata) +
  geom_density(aes(x = index)) + 
   xlim(-4,4) +
  geom_vline(xintercept = breaks$brks)
```

And this chart shows the breakpoints using the natural breaks method. 

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 3}
breaks <- classIntervals(oppdata$index, n=5, style="jenks")
ggplot(data = oppdata) +
  geom_density(aes(x = index)) + 
    xlim(-4,4) +
  geom_vline(xintercept = breaks$brks)
```

Using quintiles means that roughly 20 percent of the population will always live in high opportunity areas (since census tracts have roughly similar population), while the natural breaks (or other methods) would reflect the concentration of poverty in a smaller set of areas. 

### What is driving the Opportunity Index?

With a composite index of z-scores, it helps to see if specific variables are playing more of a role in determining the final index values. The [OECD guide to composite indicators](http://www.oecd.org/std/42495745.pdf) notes that using z-scores means that 'indicators with extreme values thus have a greater effect on the composite indicator.' That can be an issue in a state with a high degree of inequality and concentration of poverty. 

As a start, we know that many of the variables are correlated with each other - the correlation matrix below shows that several of the variables - poverty, public assistance, etc. - are correlated with each other. Job growth has almost no correlation with any of the variables. 

```{r echo = FALSE, warning = FALSE, message = FALSE}
x <- subset(oppdata[3:12], commutetime != "NA" & 
              Total.Mathematics.Avg.Scale.Score != "NA" &
              Total.Reading.Average.Scale.Score != "NA" & 
              jobchange != "NA")
#print(xtable(round(cor(x),2)), type = "html")
print(round(cor(x),2))
```

A scatterplot matrix shows the same visually - job growth and (to a lesser extent) commute time have little obvious relationship with the other variables.

```{r echo = FALSE, warning = FALSE, message = FALSE}
plot(oppdata[3:12])
```

Principal components analysis is another way to see the key factors that determine the final index. A principal components analysis of the index data shows that the first principal component dominates the results - explaining 56 percent of the overall variance in the data (first bar in the graph, first column in the table). 

```{r echo = FALSE, warning = FALSE, message = FALSE}
pca1 = prcomp(x, scale. = T)
print(summary(pca1))
plot(prcomp(x, scale = T))
```

We can look at the weights for each of the variables in the first principal component in the chart below. This shows that job growth has little influence on the first component (weight close to 0), while commute time offsets some of the other variables (positive weight). Poverty, public assistance and owner-occupied housing have the strongest weights. 

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 4}
rotation <- data.frame(pca1$rotation[,1])
qplot(data = rotation, x = pca1.rotation...1., y = row.names(rotation)) + 
  labs(x = "Weight in first principal component", y = NULL)
```

In other words: since much of the variance is explained by the first principal component and since poverty, public assistance, owner-occupied housing, educational attainment, test scores and unemployment have the most weight for that component, most of the opportunity index is described by these variables (poverty, public assistance, etc.). 

Not surprisingly, many of these variables also have very skewed distributions across Connecticut neighborhoods, and hence a more extreme range of z-scores to factor into the overall index.

Another way to look at this is to see how well these variables predict the final index values. For example, poverty alone predicts the overall index pretty well - the R-squared is 0.78 - meaning that the variation in poverty alone explains 78% of the variation in opportunity. 

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 4}
ggplot(data = subset(oppdata, poverty > -6), aes(y = index, x = poverty)) + 
  geom_point() + 
  geom_smooth(method = lm) + 
  labs(y = "Opportunity Index", x = "Poverty z-scores")
```

Overall: 
* We can re-calculate the opportunity index using Census data and state data for towns on test scores and jobs, making some concessions for data availability on the latter variables.
* Timing is a consideration - the Census data covers a different time horizon than the other variables. (But the original index used 2000 census data and jobs data for 2005 - 2008, so this may be less of a concern.)
* The index is driven largely by poverty and variables like public assistance that are strongly correlated with poverty. 
* Different ways to display the data will yield different conclusions about the landscape of opportunity in Connecticut. 
* Job growth (economic climate) has the least influence on the index as it is uncorrelated with the other variables. 

